#!/usr/bin/env python3
"""
æµ‹è¯•éšæœºæ··åˆç²¾åº¦é‡åŒ–è„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºéšæœºæ··åˆç²¾åº¦é‡åŒ–åŠŸèƒ½
"""

import sys
import os
import json
import tempfile
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.random_mixed_precision_quantization import (
    identify_layer_categories,
    create_random_quantization_config,
    save_config,
    print_config_summary
)


def create_mock_model():
    """åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿæ¨¡å‹ç”¨äºæµ‹è¯•"""
    import torch
    import torch.nn as nn
    
    class MockLinear(nn.Module):
        def __init__(self, in_features, out_features):
            super().__init__()
            self.weight = nn.Parameter(torch.randn(out_features, in_features))
            self.bias = nn.Parameter(torch.randn(out_features))
    
    class MockModel(nn.Module):
        def __init__(self):
            super().__init__()
            # Expertå±‚
            self.expert1 = MockLinear(512, 1024)
            self.expert2 = MockLinear(1024, 512)
            self.expert3 = MockLinear(512, 1024)
            
            # Attentionå±‚
            self.q_proj = MockLinear(512, 512)
            self.k_proj = MockLinear(512, 512)
            self.v_proj = MockLinear(512, 512)
            self.o_proj = MockLinear(512, 512)
            
            # å…¶ä»–å±‚
            self.linear1 = MockLinear(512, 1024)
            self.linear2 = MockLinear(1024, 512)
            self.linear3 = MockLinear(512, 256)
            
            # ç‰¹æ®Šå±‚
            self.lm_head = MockLinear(256, 1000)
            self.embed_tokens = MockLinear(1000, 256)
    
    return MockModel()


def test_layer_categorization():
    """æµ‹è¯•å±‚åˆ†ç±»åŠŸèƒ½"""
    print("æµ‹è¯•å±‚åˆ†ç±»åŠŸèƒ½...")
    print("="*50)
    
    model = create_mock_model()
    layer_categories = identify_layer_categories(model)
    
    print("å±‚åˆ†ç±»ç»“æœ:")
    for name, category in layer_categories.items():
        print(f"  {name:<20} -> {category}")
    
    # éªŒè¯åˆ†ç±»ç»“æœ
    expert_count = sum(1 for cat in layer_categories.values() if cat == "expert")
    attention_count = sum(1 for cat in layer_categories.values() if cat == "attention")
    other_count = sum(1 for cat in layer_categories.values() if cat == "other")
    
    print(f"\nåˆ†ç±»ç»Ÿè®¡:")
    print(f"  Expertå±‚: {expert_count}")
    print(f"  Attentionå±‚: {attention_count}")
    print(f"  å…¶ä»–å±‚: {other_count}")
    
    assert expert_count == 3, f"æœŸæœ›3ä¸ªExpertå±‚ï¼Œå®é™…{expert_count}ä¸ª"
    assert attention_count == 4, f"æœŸæœ›4ä¸ªAttentionå±‚ï¼Œå®é™…{attention_count}ä¸ª"
    assert other_count == 3, f"æœŸæœ›3ä¸ªå…¶ä»–å±‚ï¼Œå®é™…{other_count}ä¸ª"
    
    print("âœ“ å±‚åˆ†ç±»æµ‹è¯•é€šè¿‡")
    return layer_categories


def test_random_config_generation(layer_categories):
    """æµ‹è¯•éšæœºé…ç½®ç”ŸæˆåŠŸèƒ½"""
    print("\næµ‹è¯•éšæœºé…ç½®ç”ŸæˆåŠŸèƒ½...")
    print("="*50)
    
    # æµ‹è¯•ä¸åŒçš„æ¯”ä¾‹ç»„åˆ
    test_cases = [
        {"mxfp4_ratio": 0.3, "bf16_ratio": 0.2, "seed": 42},
        {"mxfp4_ratio": 0.5, "bf16_ratio": 0.1, "seed": 123},
        {"mxfp4_ratio": 0.1, "bf16_ratio": 0.4, "seed": 456},
    ]
    
    for i, test_case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}: mxfp4={test_case['mxfp4_ratio']:.1%}, bf16={test_case['bf16_ratio']:.1%}")
        print("-" * 40)
        
        config = create_random_quantization_config(
            layer_categories=layer_categories,
            mxfp4_ratio=test_case["mxfp4_ratio"],
            bf16_ratio=test_case["bf16_ratio"],
            group_size=32,
            seed=test_case["seed"]
        )
        
        # éªŒè¯é…ç½®ç»“æ„
        assert "default" in config, "é…ç½®ç¼ºå°‘defaultéƒ¨åˆ†"
        assert "overrides" in config, "é…ç½®ç¼ºå°‘overrideséƒ¨åˆ†"
        assert "summary" in config, "é…ç½®ç¼ºå°‘summaryéƒ¨åˆ†"
        
        # éªŒè¯æ¯”ä¾‹
        summary = config["summary"]
        total_layers = summary["total_layers"]
        mxfp4_count = summary["mxfp4_layers"]
        bf16_count = summary["bf16_layers"]
        mxfp8_count = summary["mxfp8_layers"]
        
        print(f"  æ€»å±‚æ•°: {total_layers}")
        print(f"  mxfp4: {mxfp4_count} ({mxfp4_count/total_layers:.1%})")
        print(f"  bf16: {bf16_count} ({bf16_count/total_layers:.1%})")
        print(f"  mxfp8: {mxfp8_count} ({mxfp8_count/total_layers:.1%})")
        
        # éªŒè¯æ€»æ•°
        assert mxfp4_count + bf16_count + mxfp8_count == total_layers, "å±‚æ•°æ€»æ•°ä¸åŒ¹é…"
        
        # éªŒè¯ç‰¹æ®Šå±‚
        special_layers = [o for o in config["overrides"] if o.get("category") == "special"]
        assert len(special_layers) == 3, f"æœŸæœ›3ä¸ªç‰¹æ®Šå±‚ï¼Œå®é™…{len(special_layers)}ä¸ª"
        
        print(f"  âœ“ æµ‹è¯•ç”¨ä¾‹ {i+1} é€šè¿‡")
    
    print("âœ“ éšæœºé…ç½®ç”Ÿæˆæµ‹è¯•é€šè¿‡")
    return config


def test_config_save_and_load(config):
    """æµ‹è¯•é…ç½®ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½"""
    print("\næµ‹è¯•é…ç½®ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½...")
    print("="*50)
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        temp_path = f.name
    
    try:
        # ä¿å­˜é…ç½®
        save_config(config, temp_path)
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        assert os.path.exists(temp_path), "é…ç½®æ–‡ä»¶æœªä¿å­˜"
        
        # åŠ è½½å¹¶éªŒè¯é…ç½®
        with open(temp_path, 'r', encoding='utf-8') as f:
            loaded_config = json.load(f)
        
        # éªŒè¯é…ç½®å†…å®¹
        assert loaded_config["default"] == config["default"], "defaulté…ç½®ä¸åŒ¹é…"
        assert len(loaded_config["overrides"]) == len(config["overrides"]), "overridesæ•°é‡ä¸åŒ¹é…"
        assert loaded_config["summary"]["total_layers"] == config["summary"]["total_layers"], "summaryä¸åŒ¹é…"
        
        print(f"âœ“ é…ç½®ä¿å­˜å’ŒåŠ è½½æµ‹è¯•é€šè¿‡")
        print(f"  ä¸´æ—¶æ–‡ä»¶: {temp_path}")
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_path):
            os.unlink(temp_path)


def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\næµ‹è¯•è¾¹ç•Œæƒ…å†µ...")
    print("="*50)
    
    # åˆ›å»ºæœ€å°æ¨¡å‹
    import torch
    import torch.nn as nn
    
    class MinimalModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.linear = nn.Linear(10, 10)
    
    model = MinimalModel()
    layer_categories = identify_layer_categories(model)
    
    # æµ‹è¯•æç«¯æ¯”ä¾‹
    extreme_cases = [
        {"mxfp4_ratio": 0.0, "bf16_ratio": 0.0},  # å…¨éƒ¨mxfp8
        {"mxfp4_ratio": 1.0, "bf16_ratio": 0.0},  # å…¨éƒ¨mxfp4
        {"mxfp4_ratio": 0.0, "bf16_ratio": 1.0},  # å…¨éƒ¨bf16
        {"mxfp4_ratio": 0.5, "bf16_ratio": 0.5},  # å„å ä¸€åŠ
    ]
    
    for i, case in enumerate(extreme_cases):
        print(f"æµ‹è¯•è¾¹ç•Œæƒ…å†µ {i+1}: mxfp4={case['mxfp4_ratio']:.1%}, bf16={case['bf16_ratio']:.1%}")
        
        try:
            config = create_random_quantization_config(
                layer_categories=layer_categories,
                mxfp4_ratio=case["mxfp4_ratio"],
                bf16_ratio=case["bf16_ratio"],
                group_size=32,
                seed=42
            )
            
            summary = config["summary"]
            print(f"  âœ“ æˆåŠŸç”Ÿæˆé…ç½®: mxfp4={summary['mxfp4_layers']}, bf16={summary['bf16_layers']}, mxfp8={summary['mxfp8_layers']}")
            
        except Exception as e:
            print(f"  âœ— ç”Ÿæˆé…ç½®å¤±è´¥: {e}")
    
    # æµ‹è¯•æ— æ•ˆæ¯”ä¾‹
    print("\næµ‹è¯•æ— æ•ˆæ¯”ä¾‹...")
    try:
        config = create_random_quantization_config(
            layer_categories=layer_categories,
            mxfp4_ratio=0.6,
            bf16_ratio=0.5,  # æ€»å’Œè¶…è¿‡1.0
            group_size=32,
            seed=42
        )
        print("  âœ— åº”è¯¥æŠ›å‡ºå¼‚å¸¸ä½†æœªæŠ›å‡º")
    except ValueError as e:
        print(f"  âœ“ æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {e}")
    
    print("âœ“ è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•éšæœºæ··åˆç²¾åº¦é‡åŒ–è„šæœ¬")
    print("="*60)
    
    try:
        # æµ‹è¯•å±‚åˆ†ç±»
        layer_categories = test_layer_categorization()
        
        # æµ‹è¯•éšæœºé…ç½®ç”Ÿæˆ
        config = test_random_config_generation(layer_categories)
        
        # æµ‹è¯•é…ç½®ä¿å­˜å’ŒåŠ è½½
        test_config_save_and_load(config)
        
        # æµ‹è¯•è¾¹ç•Œæƒ…å†µ
        test_edge_cases()
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("="*60)
        
        # æ˜¾ç¤ºæœ€ç»ˆé…ç½®æ‘˜è¦
        print("\næœ€ç»ˆé…ç½®æ‘˜è¦:")
        print_config_summary(config)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 